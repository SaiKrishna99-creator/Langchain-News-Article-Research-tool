{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Your_API_Key\""
      ],
      "metadata": {
        "id": "IMvZH3EGd82J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import streamlit as st\n",
        "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import UnstructuredURLLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "st.title('News Articles Research Tool ðŸ“ˆ')\n",
        "st.sidebar.title('News Article URLs')\n",
        "\n",
        "# You must set OPENAI_API_KEY in the notebook (os.environ) before launching this app.\n",
        "llm = OpenAI(temperature=0.2)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "INDEX_DIR = \"faiss_index\"  # folder that will hold index.faiss + index.pkl\n",
        "\n",
        "# --- Sidebar: collect up to 3 URLs ---\n",
        "urls = []\n",
        "for i in range(3):\n",
        "    url = st.sidebar.text_input(f'URL {i+1}', key=f'url_{i}')\n",
        "    if url:\n",
        "        urls.append(url)\n",
        "\n",
        "process_url_clicked = st.sidebar.button('Process URL')\n",
        "status = st.empty()\n",
        "\n",
        "if process_url_clicked:\n",
        "    if not urls:\n",
        "        st.warning(\"Please enter at least one URL.\")\n",
        "    else:\n",
        "        try:\n",
        "            # 1) Load data\n",
        "            status.text(\"Data Loading... Started âœ…\")\n",
        "            loader = UnstructuredURLLoader(urls=urls)\n",
        "            data = loader.load()\n",
        "\n",
        "            # 2) Split text\n",
        "            status.text(\"Text Splitting... Started âœ…\")\n",
        "            splitter = RecursiveCharacterTextSplitter(\n",
        "                separators=['\\n\\n', '\\n', '.', ','],\n",
        "                chunk_size=1000,\n",
        "                chunk_overlap=200,\n",
        "            )\n",
        "            docs = splitter.split_documents(data)\n",
        "\n",
        "            # 3) Build embeddings + FAISS\n",
        "            status.text(\"Building FAISS index... Started âœ…\")\n",
        "            vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "            # 4) Save to disk (NO pickle)\n",
        "            vectorstore.save_local(INDEX_DIR)\n",
        "            status.text(f\"Index saved to ./{INDEX_DIR} ðŸŽ‰\")\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error while processing: {e}\")\n",
        "\n",
        "# --- Ask a question ---\n",
        "query = st.text_input(\"Question:\")\n",
        "\n",
        "if query:\n",
        "    if not os.path.isdir(INDEX_DIR):\n",
        "        st.error(\"No index found. Please process URLs first.\")\n",
        "    else:\n",
        "        try:\n",
        "            # Reload the FAISS store (safe, no pickle)\n",
        "            vectorstore = FAISS.load_local(\n",
        "                INDEX_DIR,\n",
        "                embeddings,\n",
        "                allow_dangerous_deserialization=True  # needed because metadata is pickled internally\n",
        "            )\n",
        "\n",
        "            chain = RetrievalQAWithSourcesChain.from_llm(\n",
        "                llm=llm,\n",
        "                retriever=vectorstore.as_retriever()\n",
        "            )\n",
        "            result = chain({\"question\": query}, return_only_outputs=True)\n",
        "\n",
        "            st.header(\"Answer\")\n",
        "            st.write(result.get(\"answer\", \"\"))\n",
        "\n",
        "            sources = result.get(\"sources\", \"\")\n",
        "            if sources:\n",
        "                st.subheader(\"Sources:\")\n",
        "                for line in str(sources).splitlines():\n",
        "                    if line.strip():\n",
        "                        st.write(line.strip())\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error during Q&A: {e}\")\n"
      ],
      "metadata": {
        "id": "HWnuwherdmJw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e039ee1-9aa9-4671-9ec0-b714cc80cbb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kill any previous server on 8501, then start Streamlit\n",
        "!fuser -k 8501/tcp >/dev/null 2>&1 || true\n",
        "import subprocess, time\n",
        "p = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.headless=true\"])\n",
        "time.sleep(3)  # give it a moment to boot"
      ],
      "metadata": {
        "id": "0XW19bH0tnZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# close any old tunnels and agent\n",
        "for t in ngrok.get_tunnels():\n",
        "    ngrok.disconnect(t.public_url)\n",
        "ngrok.kill()\n",
        "\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(\"Streamlit app:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEJuHdHwtyiU",
        "outputId": "f56df057-09ca-4a95-a21d-a32f15b06e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app: NgrokTunnel: \"https://nonprominently-unpredisposing-burton.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}